### Origin net: 
74.3700%

### 4.A.1, Number of filters: 
76.3700% for more filters

### 4.A.2, Number of layers: 
74.2100% for one more linear layer

### 4.B, Filter size: 
74.2600% for larger fileter size

### 4.C, ReLu vs. Leaky ReLu:
75.4200%

### 4.D, Dropout vs. without Dropout:
76.0800%

### 4.E, Batch Normalization Layer:
77.3500%

### 5.A Batch size
75.6700% for larger batch size

### 5.B Learning rate
72.4100%

### 5.C Shuffling
77.8600% if shuffling
